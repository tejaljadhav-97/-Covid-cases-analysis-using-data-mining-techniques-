{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>code3</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>...</th>\n",
       "      <th>9/14/20</th>\n",
       "      <th>9/15/20</th>\n",
       "      <th>9/16/20</th>\n",
       "      <th>9/17/20</th>\n",
       "      <th>9/18/20</th>\n",
       "      <th>9/19/20</th>\n",
       "      <th>9/20/20</th>\n",
       "      <th>9/21/20</th>\n",
       "      <th>9/22/20</th>\n",
       "      <th>9/23/20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84001001</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>32.539527</td>\n",
       "      <td>-86.644082</td>\n",
       "      <td>...</td>\n",
       "      <td>1447</td>\n",
       "      <td>1463</td>\n",
       "      <td>1619</td>\n",
       "      <td>1624</td>\n",
       "      <td>1664</td>\n",
       "      <td>1673</td>\n",
       "      <td>1690</td>\n",
       "      <td>1691</td>\n",
       "      <td>1714</td>\n",
       "      <td>1715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84001003</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>30.727750</td>\n",
       "      <td>-87.722071</td>\n",
       "      <td>...</td>\n",
       "      <td>4800</td>\n",
       "      <td>4812</td>\n",
       "      <td>5003</td>\n",
       "      <td>5021</td>\n",
       "      <td>5033</td>\n",
       "      <td>5047</td>\n",
       "      <td>5061</td>\n",
       "      <td>5087</td>\n",
       "      <td>5124</td>\n",
       "      <td>5141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84001005</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>Barbour</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>31.868263</td>\n",
       "      <td>-85.387129</td>\n",
       "      <td>...</td>\n",
       "      <td>626</td>\n",
       "      <td>629</td>\n",
       "      <td>809</td>\n",
       "      <td>809</td>\n",
       "      <td>824</td>\n",
       "      <td>830</td>\n",
       "      <td>835</td>\n",
       "      <td>838</td>\n",
       "      <td>848</td>\n",
       "      <td>851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84001007</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>Bibb</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>32.996421</td>\n",
       "      <td>-87.125115</td>\n",
       "      <td>...</td>\n",
       "      <td>581</td>\n",
       "      <td>580</td>\n",
       "      <td>612</td>\n",
       "      <td>617</td>\n",
       "      <td>619</td>\n",
       "      <td>628</td>\n",
       "      <td>632</td>\n",
       "      <td>636</td>\n",
       "      <td>635</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84001009</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>Blount</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>33.982109</td>\n",
       "      <td>-86.567906</td>\n",
       "      <td>...</td>\n",
       "      <td>1128</td>\n",
       "      <td>1139</td>\n",
       "      <td>1487</td>\n",
       "      <td>1504</td>\n",
       "      <td>1527</td>\n",
       "      <td>1542</td>\n",
       "      <td>1551</td>\n",
       "      <td>1560</td>\n",
       "      <td>1573</td>\n",
       "      <td>1580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        UID iso2 iso3  code3    FIPS   Admin2 Province_State Country_Region  \\\n",
       "0  84001001   US  USA    840  1001.0  Autauga        Alabama             US   \n",
       "1  84001003   US  USA    840  1003.0  Baldwin        Alabama             US   \n",
       "2  84001005   US  USA    840  1005.0  Barbour        Alabama             US   \n",
       "3  84001007   US  USA    840  1007.0     Bibb        Alabama             US   \n",
       "4  84001009   US  USA    840  1009.0   Blount        Alabama             US   \n",
       "\n",
       "         Lat      Long_  ... 9/14/20  9/15/20  9/16/20  9/17/20  9/18/20  \\\n",
       "0  32.539527 -86.644082  ...    1447     1463     1619     1624     1664   \n",
       "1  30.727750 -87.722071  ...    4800     4812     5003     5021     5033   \n",
       "2  31.868263 -85.387129  ...     626      629      809      809      824   \n",
       "3  32.996421 -87.125115  ...     581      580      612      617      619   \n",
       "4  33.982109 -86.567906  ...    1128     1139     1487     1504     1527   \n",
       "\n",
       "   9/19/20  9/20/20  9/21/20  9/22/20  9/23/20  \n",
       "0     1673     1690     1691     1714     1715  \n",
       "1     5047     5061     5087     5124     5141  \n",
       "2      830      835      838      848      851  \n",
       "3      628      632      636      635      638  \n",
       "4     1542     1551     1560     1573     1580  \n",
       "\n",
       "[5 rows x 257 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "#SVM, Polynomial regression and bayesian regression Methods\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.colors as mcolors\n",
    "import pandas as pd \n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import datetime\n",
    "import operator \n",
    "plt.style.use('fivethirtyeight')\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "\n",
    "confirmed_df = pd.read_csv(\"C:\\\\Users\\\\Tejal\\\\Desktop\\\\733 project\\\\time_series_covid_19_confirmed.csv\")\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "confirmed_df.head()\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'sum'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-ef25e4a9a302>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mworld_cases\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdates\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mconfirmed_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfirmed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;31m# confirmed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mworld_cases\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfirmed_sum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'sum'"
     ]
    }
   ],
   "source": [
    "cols = confirmed_df.keys()\n",
    "\n",
    "\n",
    "# In[26]:\n",
    "\n",
    "\n",
    "confirmed = confirmed_df.loc[:, cols[4]:cols[-1]]\n",
    "\n",
    "\n",
    "# In[27]:\n",
    "\n",
    "\n",
    "dates = confirmed.keys()\n",
    "world_cases = []\n",
    "for i in dates:\n",
    "    confirmed_sum = str(confirmed[i]).sum()\n",
    "# confirmed\n",
    "    world_cases.append(confirmed_sum)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "\n",
    "def daily_increase(data):\n",
    "    d = [] \n",
    "    for i in range(len(data)):\n",
    "        if i == 0:\n",
    "            d.append(data[0])\n",
    "        else:\n",
    "            d.append(data[i]-data[i-1])\n",
    "    return d \n",
    "\n",
    "def moving_average(data, window_size):\n",
    "    moving_average = []\n",
    "    for i in range(len(data)):\n",
    "        if i + window_size < len(data):\n",
    "            moving_average.append(np.mean(data[i:i+window_size]))\n",
    "        else:\n",
    "            moving_average.append(np.mean(data[i:len(data)]))\n",
    "    return moving_average\n",
    "\n",
    "# window size\n",
    "window = 7\n",
    "\n",
    "# confirmed cases\n",
    "world_daily_increase = daily_increase(world_cases)\n",
    "world_confirmed_avg= moving_average(world_cases, window)\n",
    "world_daily_increase_avg = moving_average(world_daily_increase, window)\n",
    "\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "\n",
    "days_since_1_22 = np.array([i for i in range(len(dates))]).reshape(-1, 1)\n",
    "world_cases = np.array(world_cases).reshape(-1, 1)\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "\n",
    "days_in_future = 10\n",
    "future_forcast = np.array([i for i in range(len(dates)+days_in_future)]).reshape(-1, 1)\n",
    "adjusted_dates = future_forcast[:-10]\n",
    "\n",
    "\n",
    "# In[43]:\n",
    "\n",
    "\n",
    "start = '11/30/2020'\n",
    "start_date = datetime.datetime.strptime(start, '%m/%d/%Y')\n",
    "future_forcast_dates = []\n",
    "for i in range(len(future_forcast)):\n",
    "    future_forcast_dates.append((start_date + datetime.timedelta(days=i)).strftime('%m/%d/%Y'))\n",
    "\n",
    "\n",
    "# In[44]:\n",
    "\n",
    "\n",
    "# slightly modify the data to fit the model better (regression models cannot pick the pattern)\n",
    "X_train_confirmed, X_test_confirmed, y_train_confirmed, y_test_confirmed = train_test_split(days_since_1_22[50:], world_cases[50:], test_size=0.05, shuffle=False) \n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "\n",
    "# # use this to find the optimal parameters for SVR\n",
    "# c = [0.01, 0.1, 1]\n",
    "# gamma = [0.01, 0.1, 1]\n",
    "# epsilon = [0.01, 0.1, 1]\n",
    "# shrinking = [True, False]\n",
    "\n",
    "# svm_grid = {'C': c, 'gamma' : gamma, 'epsilon': epsilon, 'shrinking' : shrinking}\n",
    "\n",
    "# svm = SVR(kernel='poly', degree=3)\n",
    "# svm_search = RandomizedSearchCV(svm, svm_grid, scoring='neg_mean_squared_error', cv=3, return_train_score=True, n_jobs=-1, n_iter=30, verbose=1)\n",
    "# svm_search.fit(X_train_confirmed, y_train_confirmed)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[45]:\n",
    "\n",
    "\n",
    "# svm_confirmed = svm_search.best_estimator_\n",
    "svm_confirmed = SVR(shrinking=True, kernel='poly',gamma=0.01, epsilon=1,degree=3, C=0.1)\n",
    "svm_confirmed.fit(X_train_confirmed, y_train_confirmed)\n",
    "svm_pred = svm_confirmed.predict(future_forcast)\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "# check against testing data\n",
    "svm_test_pred = svm_confirmed.predict(X_test_confirmed)\n",
    "plt.plot(y_test_confirmed)\n",
    "plt.plot(svm_test_pred)\n",
    "plt.legend(['Test Data', 'SVM Predictions'])\n",
    "print('MAE:', mean_absolute_error(svm_test_pred, y_test_confirmed))\n",
    "print('MSE:',mean_squared_error(svm_test_pred, y_test_confirmed))\n",
    "\n",
    "\n",
    "# In[46]:\n",
    "\n",
    "\n",
    "# transform our data for polynomial regression\n",
    "poly = PolynomialFeatures(degree=4)\n",
    "poly_X_train_confirmed = poly.fit_transform(X_train_confirmed)\n",
    "poly_X_test_confirmed = poly.fit_transform(X_test_confirmed)\n",
    "poly_future_forcast = poly.fit_transform(future_forcast)\n",
    "\n",
    "bayesian_poly = PolynomialFeatures(degree=5)\n",
    "bayesian_poly_X_train_confirmed = bayesian_poly.fit_transform(X_train_confirmed)\n",
    "bayesian_poly_X_test_confirmed = bayesian_poly.fit_transform(X_test_confirmed)\n",
    "bayesian_poly_future_forcast = bayesian_poly.fit_transform(future_forcast)\n",
    "\n",
    "\n",
    "# In[47]:\n",
    "\n",
    "\n",
    "# polynomial regression\n",
    "linear_model = LinearRegression(normalize=True, fit_intercept=False)\n",
    "linear_model.fit(poly_X_train_confirmed, y_train_confirmed)\n",
    "test_linear_pred = linear_model.predict(poly_X_test_confirmed)\n",
    "linear_pred = linear_model.predict(poly_future_forcast)\n",
    "print('MAE:', mean_absolute_error(test_linear_pred, y_test_confirmed))\n",
    "print('MSE:',mean_squared_error(test_linear_pred, y_test_confirmed))\n",
    "\n",
    "\n",
    "# In[48]:\n",
    "\n",
    "\n",
    "print(linear_model.coef_)\n",
    "\n",
    "\n",
    "# In[49]:\n",
    "\n",
    "\n",
    "plt.plot(y_test_confirmed)\n",
    "plt.plot(test_linear_pred)\n",
    "plt.legend(['Test Data', 'Polynomial Regression Predictions'])\n",
    "\n",
    "\n",
    "# In[52]:\n",
    "\n",
    "\n",
    "# bayesian ridge polynomial regression\n",
    "tol = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2]\n",
    "alpha_1 = [1e-7, 1e-6, 1e-5, 1e-4, 1e-3]\n",
    "alpha_2 = [1e-7, 1e-6, 1e-5, 1e-4, 1e-3]\n",
    "lambda_1 = [1e-7, 1e-6, 1e-5, 1e-4, 1e-3]\n",
    "lambda_2 = [1e-7, 1e-6, 1e-5, 1e-4, 1e-3]\n",
    "normalize = [True, False]\n",
    "\n",
    "bayesian_grid = {'tol': tol, 'alpha_1': alpha_1, 'alpha_2' : alpha_2, 'lambda_1': lambda_1, 'lambda_2' : lambda_2, \n",
    "                 'normalize' : normalize}\n",
    "\n",
    "bayesian = BayesianRidge(fit_intercept=False)\n",
    "bayesian_search = RandomizedSearchCV(bayesian, bayesian_grid, scoring='neg_mean_squared_error', cv=3, return_train_score=True, n_jobs=-1, n_iter=40, verbose=1)\n",
    "bayesian_search.fit(bayesian_poly_X_train_confirmed, y_train_confirmed)\n",
    "\n",
    "\n",
    "# In[53]:\n",
    "\n",
    "\n",
    "bayesian_search.best_params_\n",
    "\n",
    "\n",
    "# In[54]:\n",
    "\n",
    "\n",
    "bayesian_confirmed = bayesian_search.best_estimator_\n",
    "test_bayesian_pred = bayesian_confirmed.predict(bayesian_poly_X_test_confirmed)\n",
    "bayesian_pred = bayesian_confirmed.predict(bayesian_poly_future_forcast)\n",
    "print('MAE:', mean_absolute_error(test_bayesian_pred, y_test_confirmed))\n",
    "print('MSE:',mean_squared_error(test_bayesian_pred, y_test_confirmed))\n",
    "\n",
    "\n",
    "# In[55]:\n",
    "\n",
    "\n",
    "plt.plot(y_test_confirmed)\n",
    "plt.plot(test_bayesian_pred)\n",
    "plt.legend(['Test Data', 'Bayesian Ridge Polynomial Predictions'])\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e37ad1ddb2ea8a9c0c9ab9e30876b6d524ee8b910e2337c2ddd76bc8ea8878e5"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
